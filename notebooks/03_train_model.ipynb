{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÇ Train Delay Prediction Model Training\n",
    "\n",
    "This notebook trains a machine learning model to predict train delays using historical data from Azure SQL Database.\n",
    "\n",
    "## Steps:\n",
    "1. Connect to Azure SQL Database\n",
    "2. Load and explore data\n",
    "3. Feature engineering\n",
    "4. Train model\n",
    "5. Evaluate performance\n",
    "6. Save model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pyodbc pandas numpy scikit-learn xgboost matplotlib seaborn plotly joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database Connection\n",
    "\n",
    "‚ö†Ô∏è **Security Note**: Replace these with your actual Azure SQL credentials or use environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure SQL Database connection\n",
    "# TODO: Replace with your actual database credentials\n",
    "SERVER = 'your-server.database.windows.net'\n",
    "DATABASE = 'your-database-name'\n",
    "USERNAME = 'your-username'\n",
    "PASSWORD = 'your-password'\n",
    "\n",
    "conn_str = (\n",
    "    f\"Driver={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"Server={SERVER};\"\n",
    "    f\"Database={DATABASE};\"\n",
    "    f\"UID={USERNAME};\"\n",
    "    f\"PWD={PASSWORD}\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\"‚úÖ Successfully connected to Azure SQL Database\")\nexcept Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"Please update your database credentials above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data by joining tables\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    td.train_signature_code,\n",
    "    td.from_station,\n",
    "    td.to_station,\n",
    "    td.hour,\n",
    "    td.delay,\n",
    "    s1.latitude as from_lat,\n",
    "    s1.longitude as from_long,\n",
    "    s2.latitude as to_lat,\n",
    "    s2.longitude as to_long\n",
    "FROM train_departures td\n",
    "JOIN station s1 ON td.from_station = s1.train_signature_code\n",
    "JOIN station s2 ON td.to_station = s2.train_signature_code\n",
    "WHERE td.delay IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "print(f\"üìä Loaded {len(df):,} records\")\n",
    "print(f\"üìÖ Data shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"üìà Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nüìä Delay Statistics:\")\n",
    "print(df['delay'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize delay distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Delay histogram\n",
    "axes[0,0].hist(df['delay'], bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Distribution of Delays')\n",
    "axes[0,0].set_xlabel('Delay (minutes)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Delay by hour\n",
    "hourly_delay = df.groupby('hour')['delay'].mean()\n",
    "axes[0,1].plot(hourly_delay.index, hourly_delay.values, marker='o')\n",
    "axes[0,1].set_title('Average Delay by Hour')\n",
    "axes[0,1].set_xlabel('Hour of Day')\n",
    "axes[0,1].set_ylabel('Average Delay (minutes)')\n",
    "axes[0,1].grid(True)\n",
    "\n",
    "# Top routes by delay\n",
    "df['route'] = df['from_station'] + ' ‚Üí ' + df['to_station']\n",
    "top_routes = df.groupby('route')['delay'].mean().sort_values(ascending=False).head(10)\n",
    "axes[1,0].barh(range(len(top_routes)), top_routes.values)\n",
    "axes[1,0].set_yticks(range(len(top_routes)))\n",
    "axes[1,0].set_yticklabels(top_routes.index, fontsize=8)\n",
    "axes[1,0].set_title('Top 10 Routes by Average Delay')\n",
    "axes[1,0].set_xlabel('Average Delay (minutes)')\n",
    "\n",
    "# Delay box plot by hour (simplified)\n",
    "sample_hours = [6, 8, 12, 16, 18, 20]\n",
    "delay_by_hour = [df[df['hour'] == h]['delay'].values for h in sample_hours]\n",
    "axes[1,1].boxplot(delay_by_hour, labels=sample_hours)\n",
    "axes[1,1].set_title('Delay Distribution by Key Hours')\n",
    "axes[1,1].set_xlabel('Hour of Day')\n",
    "axes[1,1].set_ylabel('Delay (minutes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create features for training\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Route identifier\n",
    "    df['route'] = df['from_station'] + '_' + df['to_station']\n",
    "    \n",
    "    # Time-based features (cyclical encoding)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    \n",
    "    # Distance calculation (approximate)\n",
    "    df['route_distance'] = np.sqrt(\n",
    "        (df['to_lat'] - df['from_lat'])**2 + \n",
    "        (df['to_long'] - df['from_long'])**2\n",
    "    ) * 111  # Rough conversion to km\n",
    "    \n",
    "    # Historical averages per route\n",
    "    route_stats = df.groupby('route')['delay'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    route_stats.columns = ['route', 'route_avg_delay', 'route_std_delay', 'route_count']\n",
    "    df = df.merge(route_stats, on='route', how='left')\n",
    "    \n",
    "    # Fill missing std with 0\n",
    "    df['route_std_delay'] = df['route_std_delay'].fillna(0)\n",
    "    \n",
    "    # Peak hour indicators\n",
    "    df['is_rush_hour'] = ((df['hour'] >= 7) & (df['hour'] <= 9)) | ((df['hour'] >= 17) & (df['hour'] <= 19))\n",
    "    df['is_night'] = (df['hour'] <= 6) | (df['hour'] >= 22)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = create_features(df)\n",
    "print(f\"‚úÖ Created features. New shape: {df_features.shape}\")\n",
    "print(f\"üìã Features: {list(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for training\n",
    "feature_columns = [\n",
    "    'hour', 'hour_sin', 'hour_cos', 'route_distance', \n",
    "    'route_avg_delay', 'route_std_delay', 'route_count',\n",
    "    'is_rush_hour', 'is_night', 'route'\n",
    "]\n",
    "\n",
    "# Create feature matrix\n",
    "X = df_features[feature_columns].copy()\n",
    "y = df_features['delay'].copy()\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['route']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[f'{col}_encoder'] = le\n",
    "\n",
    "print(f\"üéØ Target variable (delay) - Mean: {y.mean():.2f}, Std: {y.std():.2f}\")\n",
    "print(f\"üìä Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "print(\"üöÄ Training XGBoost model...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ XGBoost training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest for comparison\n",
    "print(\"üå≤ Training Random Forest model...\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Random Forest training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Ensure no negative predictions\n",
    "    y_pred = np.maximum(y_pred, 0)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f\"\\nüìä {model_name} Performance:\")\n",
    "    print(f\"   RMSE: {rmse:.2f} minutes\")\n",
    "    print(f\"   MAE:  {mae:.2f} minutes\")\n",
    "    print(f\"   R¬≤:   {r2:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': y_pred,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "xgb_results = evaluate_model(xgb_model, X_test, y_test, \"XGBoost\")\n",
    "rf_results = evaluate_model(rf_model, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# XGBoost\n",
    "axes[0].scatter(y_test, xgb_results['predictions'], alpha=0.5, s=1)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Delay (minutes)')\n",
    "axes[0].set_ylabel('Predicted Delay (minutes)')\n",
    "axes[0].set_title(f'XGBoost: R¬≤ = {xgb_results[\"r2\"]:.3f}')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Random Forest\n",
    "axes[1].scatter(y_test, rf_results['predictions'], alpha=0.5, s=1)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Delay (minutes)')\n",
    "axes[1].set_ylabel('Predicted Delay (minutes)')\n",
    "axes[1].set_title(f'Random Forest: R¬≤ = {rf_results[\"r2\"]:.3f}')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_names = X.columns\n",
    "\n",
    "# XGBoost feature importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=xgb_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Most Important Features (XGBoost)')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç Top 5 Most Important Features:\")\n",
    "for i, row in xgb_importance.head().iterrows():\n",
    "    print(f\"   {row['feature']}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Selection and Saving"
   ]
  },
  {
   "cell_type": "code
