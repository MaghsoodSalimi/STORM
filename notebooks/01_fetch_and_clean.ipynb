{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f36180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import importlib\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641984d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    " \n",
    "\n",
    "API_KEY = \"cc099cfca8464b55b73357eec92da761\"\n",
    "\n",
    "def run_query(query):\n",
    "  try:\n",
    "      response = requests.post(\n",
    "          url=\"https://api.trafikinfo.trafikverket.se/v2/data.json\",\n",
    "          data=query.encode(\"utf-8\"),\n",
    "          headers={\"Content-Type\": \"text/xml\"},\n",
    "      )\n",
    "\n",
    "      # Check for HTTP errors\n",
    "      response.raise_for_status()\n",
    "\n",
    "      # Try parsing JSON\n",
    "      try:\n",
    "          data = response.json()\n",
    "      except json.JSONDecodeError as e:\n",
    "          print(\"‚ùå Failed to parse JSON response:\")\n",
    "          print(response.text)\n",
    "          raise e\n",
    "\n",
    "      # Check for API-level errors in the response\n",
    "      if \"RESPONSE\" in data and \"RESULT\" in data[\"RESPONSE\"]:\n",
    "          result = data[\"RESPONSE\"][\"RESULT\"][0]\n",
    "          if \"ERROR\" in result:\n",
    "              print(\"‚ö†Ô∏è API Error:\")\n",
    "              print(json.dumps(result[\"ERROR\"], indent=2))\n",
    "          else:\n",
    "              print(\"‚úÖ Success\")\n",
    "      else:\n",
    "          print(\"‚ö†Ô∏è Unexpected response format:\")\n",
    "          print(json.dumps(data, indent=2))\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "      print(\"üö® HTTP Request failed:\")\n",
    "      print(e)\n",
    "  return response\n",
    "\n",
    "def fetch_stations():\n",
    "    query = f\"\"\"\n",
    "    <REQUEST>\n",
    "        <LOGIN authenticationkey='{API_KEY}' />\n",
    "          <QUERY  objecttype=\"TrainStation\" namespace=\"rail.infrastructure\" schemaversion=\"1.5\">\n",
    "            <FILTER>\n",
    "    \n",
    "            </FILTER>\n",
    "            <EXCLUDE>LocationInformationText</EXCLUDE>\n",
    "            <EXCLUDE>ModifiedTime</EXCLUDE>\n",
    "            <EXCLUDE>PlatformLine</EXCLUDE>\n",
    "            \n",
    "          </QUERY>\n",
    "    </REQUEST>\n",
    "    \"\"\"\n",
    "\n",
    "    print(query)\n",
    "    response = run_query(query)\n",
    "\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "\n",
    "    data = response.json()[\"RESPONSE\"][\"RESULT\"][0][\"TrainStation\"]\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def fetch_departures(station_code=\"Cst\"):\n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    one_hour_later = (now + timedelta(hours=1)).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "    print (now_str)\n",
    "\n",
    "    from_time = '2025-04-01T00:00:00'\n",
    "                  \n",
    "    to_time = '2025-05-01T00:00:00'\n",
    "\n",
    "    query = f\"\"\"\n",
    "    <REQUEST>\n",
    "      <LOGIN authenticationkey='{API_KEY}' />\n",
    "      <QUERY objecttype='TrainAnnouncement' orderby='AdvertisedTimeAtLocation' schemaversion=\"1.9\" >  \n",
    "        <FILTER>\n",
    "          <AND>\n",
    "            <EQ name='Advertised' value='true'  />\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            <EQ name='ActivityType' value='Avgang' />\n",
    "          </AND>\n",
    "        </FILTER>\n",
    "        <EXCLUDE>ActivityId</EXCLUDE>\n",
    "        <EXCLUDE>WebLink</EXCLUDE>\n",
    "        <EXCLUDE>WebLinkName</EXCLUDE>\n",
    "        <EXCLUDE>OperationalTransportIdentifiers</EXCLUDE>\n",
    "        <EXCLUDE>OtherInformation</EXCLUDE>\n",
    "        <EXCLUDE>ViaToLocation</EXCLUDE>\n",
    "        <EXCLUDE>MobileWebLink</EXCLUDE>\n",
    "        <EXCLUDE>TimeAtLocationWithSeconds</EXCLUDE>\n",
    "        <EXCLUDE>TypeOfTraffic</EXCLUDE>\n",
    "        <EXCLUDE>ProductInformation</EXCLUDE>\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "      </QUERY>\n",
    "    </REQUEST>\n",
    "    \"\"\"\n",
    "\n",
    "    print(query)\n",
    "    response = run_query(query)\n",
    "\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "\n",
    "    data = response.json()[\"RESPONSE\"][\"RESULT\"][0][\"TrainAnnouncement\"]\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "317538a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-26T21:54:02\n",
      "\n",
      "    <REQUEST>\n",
      "      <LOGIN authenticationkey='cc099cfca8464b55b73357eec92da761' />\n",
      "      <QUERY objecttype='TrainAnnouncement' orderby='AdvertisedTimeAtLocation' schemaversion=\"1.9\" >  \n",
      "        <FILTER>\n",
      "          <AND>\n",
      "            <EQ name='Advertised' value='true'  />\n",
      "\n",
      "            \n",
      "            \n",
      "            \n",
      "            <EQ name='ActivityType' value='Avgang' />\n",
      "          </AND>\n",
      "        </FILTER>\n",
      "        <EXCLUDE>ActivityId</EXCLUDE>\n",
      "        <EXCLUDE>WebLink</EXCLUDE>\n",
      "        <EXCLUDE>WebLinkName</EXCLUDE>\n",
      "        <EXCLUDE>OperationalTransportIdentifiers</EXCLUDE>\n",
      "        <EXCLUDE>OtherInformation</EXCLUDE>\n",
      "        <EXCLUDE>ViaToLocation</EXCLUDE>\n",
      "        <EXCLUDE>MobileWebLink</EXCLUDE>\n",
      "        <EXCLUDE>TimeAtLocationWithSeconds</EXCLUDE>\n",
      "        <EXCLUDE>TypeOfTraffic</EXCLUDE>\n",
      "        <EXCLUDE>ProductInformation</EXCLUDE>\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "      </QUERY>\n",
      "    </REQUEST>\n",
      "    \n",
      "‚ö†Ô∏è API Error:\n",
      "{\n",
      "  \"SOURCE\": \"ResponseStreamer\",\n",
      "  \"MESSAGE\": \"Maximum response size is reached. The result is not complete.\"\n",
      "}\n",
      "  ActivityType  Advertised       AdvertisedTimeAtLocation  \\\n",
      "0       Avgang        True  2025-05-23T00:00:00.000+02:00   \n",
      "1       Avgang        True  2025-05-23T00:00:00.000+02:00   \n",
      "2       Avgang        True  2025-05-23T00:03:00.000+02:00   \n",
      "3       Avgang        True  2025-05-23T00:04:00.000+02:00   \n",
      "4       Avgang        True  2025-05-23T00:04:00.000+02:00   \n",
      "\n",
      "  AdvertisedTrainIdent  Canceled  Deleted               DepartureDateOTN  \\\n",
      "0                68472     False    False  0001-01-01T00:00:00.000+01:00   \n",
      "1                 2983     False    False  2025-05-23T00:00:00.000+02:00   \n",
      "2                52277     False    False  2025-05-23T00:00:00.000+02:00   \n",
      "3                 3594     False    False  2025-05-23T00:00:00.000+02:00   \n",
      "4                 2983     False    False  2025-05-23T00:00:00.000+02:00   \n",
      "\n",
      "                                         Deviation  \\\n",
      "0      [{'Code': 'ANA006', 'Description': 'Buss'}]   \n",
      "1  [{'Code': 'ANA031', 'Description': 'Kort t√•g'}]   \n",
      "2  [{'Code': 'ANA031', 'Description': 'Kort t√•g'}]   \n",
      "3                                              NaN   \n",
      "4  [{'Code': 'ANA031', 'Description': 'Kort t√•g'}]   \n",
      "\n",
      "   EstimatedTimeIsPreliminary  \\\n",
      "0                       False   \n",
      "1                       False   \n",
      "2                       False   \n",
      "3                       False   \n",
      "4                       False   \n",
      "\n",
      "                                        FromLocation  ...  \\\n",
      "0  [{'LocationName': 'Tip', 'Priority': 1, 'Order...  ...   \n",
      "1  [{'LocationName': 'Mr', 'Priority': 1, 'Order'...  ...   \n",
      "2  [{'LocationName': 'S√∂c', 'Priority': 1, 'Order...  ...   \n",
      "3  [{'LocationName': 'Lr', 'Priority': 1, 'Order'...  ...   \n",
      "4  [{'LocationName': 'Mr', 'Priority': 1, 'Order'...  ...   \n",
      "\n",
      "             LocationDateTimeOTN OperationalTrainNumber  \\\n",
      "0                            NaN                    NaN   \n",
      "1  2025-05-23T00:00:00.000+02:00                   2983   \n",
      "2  2025-05-23T00:03:00.000+02:00                  25277   \n",
      "3  2025-05-23T00:04:00.000+02:00                   3594   \n",
      "4  2025-05-23T00:04:00.000+02:00                   2983   \n",
      "\n",
      "                  TimeAtLocation  TrainOwner        EstimatedTimeAtLocation  \\\n",
      "0                            NaN         NaN                            NaN   \n",
      "1  2025-05-23T00:03:00.000+02:00         SLL                            NaN   \n",
      "2  2025-05-23T00:03:00.000+02:00         SLL                            NaN   \n",
      "3  2025-05-23T00:04:00.000+02:00    VASTTRAF                            NaN   \n",
      "4  2025-05-23T00:08:00.000+02:00         SLL  2025-05-23T00:06:00.000+02:00   \n",
      "\n",
      "   Booking Service TrainComposition PlannedEstimatedTimeAtLocation  \\\n",
      "0      NaN     NaN              NaN                            NaN   \n",
      "1      NaN     NaN              NaN                            NaN   \n",
      "2      NaN     NaN              NaN                            NaN   \n",
      "3      NaN     NaN              NaN                            NaN   \n",
      "4      NaN     NaN              NaN                            NaN   \n",
      "\n",
      "  ViaFromLocation  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate 'DelayMinutes'\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDelayMinutes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimeAtLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdvertisedTimeAtLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_seconds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Save CSV\u001b[39;00m\n\u001b[1;32m     28\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/train_departures.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "df_raw = fetch_departures()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(df_raw)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Create data/raw folder if needed\n",
    "Path(\"../data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    " \n",
    "# Convert time columns to datetime\n",
    "df['AdvertisedTimeAtLocation'] = pd.to_datetime(df['AdvertisedTimeAtLocation'])\n",
    "df['TimeAtLocation'] = pd.to_datetime(df['TimeAtLocation'])\n",
    "\n",
    "# Create 'Hour' column (rounded to the nearest hour)\n",
    "df['Hour'] = df['AdvertisedTimeAtLocation'].dt.floor('h')\n",
    "df['Hour'] = df['Hour'].dt.hour\n",
    "\n",
    "# Calculate 'DelayMinutes'\n",
    "df['DelayMinutes'] = ((df['TimeAtLocation'] - df['AdvertisedTimeAtLocation']).dt.total_seconds() / 60).round().astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"../data/raw/train_departures.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da948d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <REQUEST>\n",
      "        <LOGIN authenticationkey='cc099cfca8464b55b73357eec92da761' />\n",
      "          <QUERY  objecttype=\"TrainStation\" namespace=\"rail.infrastructure\" schemaversion=\"1.5\">\n",
      "            <FILTER>\n",
      "    \n",
      "            </FILTER>\n",
      "            <EXCLUDE>LocationInformationText</EXCLUDE>\n",
      "            <EXCLUDE>ModifiedTime</EXCLUDE>\n",
      "            <EXCLUDE>PlatformLine</EXCLUDE>\n",
      "            \n",
      "          </QUERY>\n",
      "    </REQUEST>\n",
      "    \n",
      "‚úÖ Success\n",
      "   Advertised AdvertisedLocationName AdvertisedShortLocationName  \\\n",
      "0        True               Alings√•s                    Alings√•s   \n",
      "1        True               Anneberg                    Anneberg   \n",
      "2        True           Abisko √ñstra                    Abisko √ñ   \n",
      "3        True                  Aneby                       Aneby   \n",
      "4        True                  Aspen                       Aspen   \n",
      "\n",
      "  PrimaryLocationCode CountryCode CountyNo  Deleted LocationSignature  \\\n",
      "0                 119          SE     [14]    False                 A   \n",
      "1                 155          SE     [13]    False                Ag   \n",
      "2                 106          SE     [25]    False                Ak   \n",
      "3                 151          SE      [6]    False               Any   \n",
      "4                 203          SE     [14]    False               Apn   \n",
      "\n",
      "   Prognosticated OfficialLocationName     Geometry.SWEREF99TM  \\\n",
      "0            True             Alings√•s  POINT (353852 6423240)   \n",
      "1            True             Anneberg  POINT (326462 6381052)   \n",
      "2            True         Abisko √∂stra  POINT (657629 7586635)   \n",
      "3            True                Aneby  POINT (488831 6410627)   \n",
      "4            True                Aspen  POINT (335801 6404715)   \n",
      "\n",
      "                                 Geometry.WGS84  \n",
      "0  POINT (12.532185446104254 57.92690516743591)  \n",
      "1  POINT (12.100776421963255 57.53862892560069)  \n",
      "2   POINT (18.83034620604857 68.34864107860172)  \n",
      "3  POINT (14.811896253047214 57.83743457399663)  \n",
      "4   POINT (12.240512226679396 57.7544220544198)  \n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "df_raw = fetch_stations()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(df_raw)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Create data/raw folder if needed\n",
    "Path(\"../data/raw\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save CSV\n",
    "df.to_csv(\"../data/raw/stations.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
